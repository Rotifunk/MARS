{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)  # CUDA 버전을 출력 (None일 경우 CPU 전용)\n",
    "print(torch.cuda.is_available())  # False일 경우 CUDA 사용 불가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def modify_paths(json_data, json_filename):\n",
    "    \"\"\"JSON 파일의 경로를 수정하는 함수\"\"\"\n",
    "    dialogs = json_data['dataSet']['dialogs']\n",
    "    \n",
    "    for dialog in dialogs:\n",
    "        # 기존 경로에서 필요한 부분만 추출\n",
    "        audio_parts = dialog['audioPath'].split('/')\n",
    "        text_parts = dialog['textPath'].split('/')\n",
    "        \n",
    "        # 새로운 경로 형식으로 변경\n",
    "        dialog['audioPath'] = f\"MARS/All_Datas/J91/{json_filename}/{audio_parts[-1]}\"\n",
    "        dialog['textPath'] = f\"MARS/All_Datas/J91/{json_filename}/{text_parts[-1]}\"\n",
    "    \n",
    "    return json_data\n",
    "\n",
    "# JSON 파일 순차적으로 처리\n",
    "for i in range(7727, 7868):\n",
    "    json_filename = f\"S{str(i).zfill(8)}\"  # S00007727 형식으로 파일명 생성\n",
    "    \n",
    "    # JSON 파일 읽기\n",
    "    with open(f'/content/drive/Othercomputers/내 노트북/MARS/All_Datas/J91/{json_filename}/{json_filename}.json', 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # 경로 수정\n",
    "    modified_data = modify_paths(data, json_filename)\n",
    "    \n",
    "    # 수정된 JSON 파일 저장\n",
    "    with open(f'/content/drive/Othercomputers/내 노트북/MARS/All_Datas/J91/{json_filename}/{json_filename}.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(modified_data, f, ensure_ascii=False, indent='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pqstv\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\pqstv\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50360]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind. He has grave doubts whether Sir Frederick Layton's work is really Greek after all, and can discover in it but little of rocky Ithaca. Linnell's pictures are a sort of Up Guards and Adam paintings, and Mason's exquisite idylls are as national as a jingo poem. Mr. Burkett Foster's landscapes smile at one much in the same way that Mr. Carker used to flash his teeth. And Mr. John Collier gives his sitter a cheerful slap on the back before he says, like a shampooer in a Turkish bath, Next man!\n",
      "[0.0s -> 5.3s]  Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel.\n",
      "[6.4s -> 10.1s]  Nor is Mr. Quilter's manner less interesting than his matter.\n",
      "[11.0s -> 17.6s]  He tells us that at this festive season of the year, with Christmas and roast beef looming before us,\n",
      "[18.5s -> 22.6s]  similes drawn from eating and its results occur most readily to the mind.\n",
      "[23.1s -> 28.7s]  He has grave doubts whether Sir Frederick Layton's work is really Greek after all,\n",
      "[29.1s -> 32.5s]  and can discover in it but little of rocky Ithaca.\n",
      "[33.6s -> 37.9s]  Linnell's pictures are a sort of Up Guards and Adam paintings,\n",
      "[37.9s -> 42.9s]  and Mason's exquisite idylls are as national as a jingo poem.\n",
      "[44.5s -> 47.6s]  Mr. Burkett Foster's landscapes smile at one\n",
      "[47.6s -> 51.5s]  much in the same way that Mr. Carker used to flash his teeth.\n",
      "[52.5s -> 57.2s]  And Mr. John Collier gives his sitter a cheerful slap on the back\n",
      "[57.2s -> 60.7s]  before he says, like a shampooer in a Turkish bath,\n",
      "[61.2s -> 61.9s]  Next man!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_cer(reference, hypothesis):\n",
    "    \"\"\"문자 오류율(CER) 계산\"\"\"\n",
    "    if not reference or not hypothesis:\n",
    "        return 1.0  # 빈 문자열인 경우 최대 오류율 반환\n",
    "    \n",
    "    # 문자 단위로 분리\n",
    "    ref_chars = list(reference.replace(' ', ''))  # 공백 제거 후 문자 분리\n",
    "    hyp_chars = list(hypothesis.replace(' ', ''))\n",
    "    \n",
    "    if not ref_chars:  # 참조 텍스트가 비어있는 경우\n",
    "        return 1.0\n",
    "    \n",
    "    # Levenshtein 거리 계산\n",
    "    distances = np.zeros((len(ref_chars) + 1, len(hyp_chars) + 1))\n",
    "    \n",
    "    # 첫 행과 열 초기화\n",
    "    for i in range(len(ref_chars) + 1):\n",
    "        distances[i][0] = i\n",
    "    for j in range(len(hyp_chars) + 1):\n",
    "        distances[0][j] = j\n",
    "    \n",
    "    # 거리 계산\n",
    "    for i in range(1, len(ref_chars) + 1):\n",
    "        for j in range(1, len(hyp_chars) + 1):\n",
    "            if ref_chars[i-1] == hyp_chars[j-1]:\n",
    "                distances[i][j] = distances[i-1][j-1]\n",
    "            else:\n",
    "                distances[i][j] = min(distances[i-1][j] + 1,    # 삭제\n",
    "                                    distances[i][j-1] + 1,      # 삽입\n",
    "                                    distances[i-1][j-1] + 1)    # 대체\n",
    "    \n",
    "    # CER 계산\n",
    "    return float(distances[len(ref_chars)][len(hyp_chars)]) / len(ref_chars)\n",
    "\n",
    "class AudioTextDataset(Dataset):\n",
    "    \"\"\"오디오-텍스트 데이터셋\"\"\"\n",
    "    def __init__(self, base_path, file_list):\n",
    "        self.base_path = base_path\n",
    "        self.samples = []\n",
    "        \n",
    "        # 데이터 준비\n",
    "        for json_filename in file_list:\n",
    "            json_path = os.path.join(base_path, json_filename, f\"{json_filename}.json\")\n",
    "            try:\n",
    "                with open(json_path, 'r', encoding='utf-8-sig') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                for dialog in data['dataSet']['dialogs']:\n",
    "                    audio_parts = dialog['audioPath'].split('/')\n",
    "                    text_parts = dialog['textPath'].split('/')\n",
    "                    \n",
    "                    audio_path = os.path.join(base_path, json_filename, audio_parts[-1])\n",
    "                    text_path = os.path.join(base_path, json_filename, text_parts[-1])\n",
    "                    \n",
    "                    if os.path.exists(audio_path) and os.path.exists(text_path):\n",
    "                        self.samples.append({\n",
    "                            'json_filename': json_filename,\n",
    "                            'audio_path': audio_path,\n",
    "                            'text_path': text_path,\n",
    "                            'new_audio_path': f\"MARS/All_Datas/J91/{json_filename}/{audio_parts[-1]}\",\n",
    "                            'new_text_path': f\"MARS/All_Datas/J91/{json_filename}/{text_parts[-1]}\"\n",
    "                        })\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {json_filename}: {str(e)}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        try:\n",
    "            # 오디오 로드\n",
    "            audio, sr = librosa.load(sample['audio_path'], sr=16000)\n",
    "            \n",
    "            # 텍스트 로드\n",
    "            with open(sample['text_path'], 'r', encoding='utf-8') as f:\n",
    "                text = f.read().strip()\n",
    "            \n",
    "            return {\n",
    "                'json_filename': sample['json_filename'],\n",
    "                'audio': audio,\n",
    "                'text': text,\n",
    "                'new_audio_path': sample['new_audio_path'],\n",
    "                'new_text_path': sample['new_text_path']\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading sample {idx}: {str(e)}\")\n",
    "            # 에러 발생 시 더미 데이터 반환\n",
    "            return {\n",
    "                'json_filename': sample['json_filename'],\n",
    "                'audio': np.zeros(16000),  # 1초 길이의 무음\n",
    "                'text': '',\n",
    "                'new_audio_path': sample['new_audio_path'],\n",
    "                'new_text_path': sample['new_text_path']\n",
    "            }\n",
    "            \n",
    "def collate_fn(batch):\n",
    "    \"\"\"배치 데이터 처리\"\"\"\n",
    "    return {\n",
    "        'json_filename': [item['json_filename'] for item in batch],\n",
    "        'audio': [item['audio'] for item in batch],\n",
    "        'text': [item['text'] for item in batch],\n",
    "        'new_audio_path': [item['new_audio_path'] for item in batch],\n",
    "        'new_text_path': [item['new_text_path'] for item in batch]\n",
    "    }\n",
    "\n",
    "def update_json_files(results, base_path):\n",
    "    \"\"\"JSON 파일 업데이트\"\"\"\n",
    "    for filename in results:\n",
    "        json_path = os.path.join(base_path, filename, f\"{filename}.json\")\n",
    "        try:\n",
    "            with open(json_path, 'r', encoding='utf-8-sig') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            # 경로 업데이트\n",
    "            for dialog in data['dataSet']['dialogs']:\n",
    "                audio_parts = dialog['audioPath'].split('/')\n",
    "                text_parts = dialog['textPath'].split('/')\n",
    "                dialog['audioPath'] = f\"MARS/All_Datas/J91/{filename}/{audio_parts[-1]}\"\n",
    "                dialog['textPath'] = f\"MARS/All_Datas/J91/{filename}/{text_parts[-1]}\"\n",
    "            \n",
    "            # 수정된 JSON 저장\n",
    "            with open(json_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(data, f, ensure_ascii=False, indent='\\t')\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error updating {filename}: {str(e)}\")\n",
    "\n",
    "def save_to_csv(results_data, output_path='transcription_results.csv'):\n",
    "    \"\"\"전사 결과를 CSV 파일로 저장\"\"\"\n",
    "    # 결과 데이터 저장용 리스트\n",
    "    rows = []\n",
    "    \n",
    "    for batch_data in results_data:\n",
    "        filename = batch_data['filename']\n",
    "        reference = batch_data['reference']\n",
    "        transcription = batch_data['transcription']\n",
    "        cer = batch_data['cer']\n",
    "        \n",
    "        rows.append({\n",
    "            'Filename': filename,\n",
    "            'Reference': reference,\n",
    "            'Transcription': transcription,\n",
    "            'CER': cer\n",
    "        })\n",
    "    \n",
    "    # DataFrame 생성 및 저장\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\n전사 결과가 {output_path}에 저장되었습니다.\")\n",
    "\n",
    "def main():\n",
    "    # CUDA 설정\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "    \n",
    "    print(\"모델 로딩 중...\")\n",
    "    # Whisper 모델 로드\n",
    "    model_id = \"openai/whisper-large-v3\"\n",
    "    model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "        model_id, \n",
    "        torch_dtype=torch_dtype, \n",
    "        low_cpu_mem_usage=True, \n",
    "        use_safetensors=True,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    \n",
    "    processor = AutoProcessor.from_pretrained(model_id)\n",
    "    \n",
    "    pipe = pipeline(\n",
    "        \"automatic-speech-recognition\",\n",
    "        model=model,\n",
    "        tokenizer=processor.tokenizer,\n",
    "        feature_extractor=processor.feature_extractor,\n",
    "        torch_dtype=torch_dtype,\n",
    "        batch_size=16,  # 배치 크기 증가\n",
    "        return_timestamps=True,\n",
    "        generate_kwargs={\n",
    "            \"task\": \"transcribe\", \n",
    "            \"language\": \"ko\"\n",
    "        }\n",
    "    )\n",
    "    print(\"모델 로딩 완료!\")\n",
    "    \n",
    "    # 데이터 준비\n",
    "    base_path = '/content/drive/Othercomputers/내 노트북/MARS/All_Datas/J91'\n",
    "    file_list = [f\"S{str(num).zfill(8)}\" for num in range(7727, 7867 + 1)]\n",
    "    \n",
    "    # 데이터셋 및 데이터로더 생성\n",
    "    dataset = AudioTextDataset(base_path, file_list)\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=16,  # 배치 크기\n",
    "        shuffle=False, \n",
    "        num_workers=4,  # 데이터 로딩 워커 수\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=True  # CUDA 전송 최적화\n",
    "    )\n",
    "    \n",
    "    # 결과 저장용\n",
    "    results = {}\n",
    "    detailed_results = []  # 상세 전사 결과 저장용\n",
    "    \n",
    "    # 처리 진행\n",
    "    print(f\"총 샘플 수: {len(dataset)}\")\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"음성 처리 중\"):\n",
    "            try:\n",
    "                # Whisper로 음성인식\n",
    "                transcriptions = pipe(batch['audio'])\n",
    "                \n",
    "                # CER 계산 및 결과 저장\n",
    "                for filename, ref_text, trans in zip(batch['json_filename'], batch['text'], transcriptions):\n",
    "                    cer = calculate_cer(ref_text, trans['text'])\n",
    "                    \n",
    "                    if filename not in results:\n",
    "                        results[filename] = {'cer_scores': [], 'num_processed': 0}\n",
    "                    \n",
    "                    results[filename]['cer_scores'].append(cer)\n",
    "                    results[filename]['num_processed'] += 1\n",
    "                    \n",
    "                    # 상세 전사 결과 저장\n",
    "                    detailed_results.append({\n",
    "                        'filename': filename,\n",
    "                        'reference': ref_text,\n",
    "                        'transcription': trans['text'],\n",
    "                        'cer': cer\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing batch: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    # JSON 파일 업데이트\n",
    "    print(\"JSON 파일 업데이트 중...\")\n",
    "    update_json_files(results, base_path)\n",
    "    \n",
    "    # 결과 정리\n",
    "    final_results = []\n",
    "    for filename, data in results.items():\n",
    "        avg_cer = np.mean(data['cer_scores']) if data['cer_scores'] else None\n",
    "        final_results.append({\n",
    "            'filename': filename,\n",
    "            'status': 'Success',\n",
    "            'avg_cer': float(avg_cer) if avg_cer is not None else None,\n",
    "            'num_processed': data['num_processed']\n",
    "        })\n",
    "    \n",
    "    # 통계 출력\n",
    "    successful_files = sum(1 for r in final_results if r['avg_cer'] is not None)\n",
    "    print(f\"\\n처리 완료된 파일: {successful_files}/{len(file_list)}\")\n",
    "    \n",
    "    valid_results = [r['avg_cer'] for r in final_results if r['avg_cer'] is not None]\n",
    "    if valid_results:\n",
    "        total_avg_cer = np.mean(valid_results)\n",
    "        print(f\"전체 평균 CER: {total_avg_cer:.4f}\")\n",
    "    \n",
    "    # JSON 결과 저장\n",
    "    result_path = 'processing_results.json'\n",
    "    with open(result_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(final_results, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"\\n상세 결과가 {result_path}에 저장되었습니다.\")\n",
    "    \n",
    "    # CSV 파일로 전사 결과 저장\n",
    "    save_to_csv(detailed_results, 'transcription_results.csv')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
